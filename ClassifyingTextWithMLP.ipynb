{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 다층 퍼셉트론(MultiLayer Perceptron, MLP)으로 텍스트 분류하기\n",
    "\n",
    "## 1. 다층 퍼셉트론(MultiLayer Perceptron, MLP)\n",
    "\n",
    "앞서 단층 퍼셉트론의 형태에서 은닉층이 1개 이상 추가된 신경망을 다층 퍼셉트론(MLP)이라고 한다고 배웠습니다. 다층 퍼셉트론은 피드 포워드 신경망(Feed Forward Neural Network, FFNN)의 가장 기본적인 형태입니다. 피드 포워드 신경망은 입력층에서 출력층으로 오직 한 방향으로만 연산 방향이 정해져 있는 신경망을 말합니다.\n",
    "\n",
    "뒤에서는 순환 신경망(RNN)과 분산 표현(distributed representation)이라는 새로운 개념들을 사용하여 각종 자연어 처리 실습을 하게 될텐데, 이번 챕터의 목적은 위 두 가지 개념없이 지금까지 배운 개념만으로도 자연어 처리를 할 수 있다는 것을 보여주기 위함입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 케라스의 texts_to_matrix() 이해하기\n",
    "\n",
    "MLP로 텍스트 분류를 수행하기 전에 이번에 사용할 도구인 케라스 Tokenizer의 texts_to_matrx()를 이해해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = ['먹고 싶은 사과', '먹고 싶은 바나나', '길고 노란 바나나 바나나', '저는 과일이 좋아요']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'바나나': 1, '먹고': 2, '싶은': 3, '사과': 4, '길고': 5, '노란': 6, '저는': 7, '과일이': 8, '좋아요': 9}\n"
     ]
    }
   ],
   "source": [
    "t = Tokenizer()\n",
    "t.fit_on_texts(texts)\n",
    "print(t.word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 단어에 숫자 1부터 시작하는 정수 인덱스가 부여되었습니다. 이제 텍스트 데이터에 texts_to_matrix()를 사용해보겠습니다. texts_to_matrix()란 이름에서 알 수 있지만, 이 도구는 입력된 텍스트 데이터로부터 행렬(matrix)를 만드는 도구입니다. texts_to_matrx()는 총 4개의 모드를 지원하는데 각 모드는 'binary', 'count', 'freq', 'tfidf'로 총 4개입니다. 우선 'count' 모드를 사용해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1. 1. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 2. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(t.texts_to_matrix(texts, mode = 'count')) # texts_to_matrix의 입력으로 texts를 넣고, 모드는 'count'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 경우는 총 4개의 모드 중에서 'count' 모드를 사용했을 경우입니다. 'count'를 사용하면 우리가 앞서 배운 문서 단어 행렬(Document-Term Matrix, DTM)을 생성합니다. DTM에서의 인덱스는 앞서 확인한 word_index의 결과입니다.\n",
    "\n",
    "다만 주의할 점은 각 단어에 부여되는 인덱스는 1부터 시작하는 반면에 완성되는 행렬의 인덱스는 0부터 시작합니다. 실제로 단어의 개수는 9개였지만 완성된 행렬의 열의 개수는 10개인 것과 첫번째 열은 모든 행에서 값이 0인 것을 볼 수 있습니다. 인덱스 0에는 그 어떤 단어도 할당되지 않았기 때문입니다.\n",
    "\n",
    "우선, 네번째 행을 보겠습니다. 네번째 행은 테스트 데이터에서 네번째 문장을 의미합니다. 네번째 행은 8번째 열, 9번째 열, 10번째 열에서 1의 값을 가집니다. 이는 7번 단어, 8번 단어, 9번 단어가 네번째 문장에서 1개씩 존재함을 의미합니다. 위에서 정수 인코딩 된 결과를 보면 7번 단어는 '저는', 8번 단어는 '과일이', 9번 단어는 '좋아요'입니다. 세번째 행의 첫번째 열의 값은 2인데, 이는 세번째 문장에서 1번 인덱스를 가진 바나나가 두 번 등장했기 때문입니다.\n",
    "\n",
    "앞서 배웠듯이 DTM은 bag of words를 기반으로 하므로 단어 순서 정보는 보존되지 않습니다. 사실 더 구체적으로는 4개의 모든 모드에서 단어 순서 정보는 보존되지 않습니다. 이제 'binary' 모드를 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1. 1. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(t.texts_to_matrix(texts, mode = 'binary'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DTM과 결과가 매우 유사해보입니다. 다만 세번째 행, 두번째 열의 값이 DTM에서는 2였는데 여기서는 1로 바뀌었습니다. 그 이유는 'binary' 모드는 해당 단어가 존재하는지만 관심을 가지고 해당 단어가 몇 개였는지는 무시하기 때문입니다. 해당 단어가 존재하면 1, 단어가 존재하지 않으면 0의 값을 가집니다. 즉, 단어의 존재 유무로만 행렬을 표현합니다. 이제 'tfidf' 모드를 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.   0.   0.85 0.85 1.1  0.   0.   0.   0.   0.  ]\n",
      " [0.   0.85 0.85 0.85 0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   1.43 0.   0.   0.   1.1  1.1  0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   1.1  1.1  1.1 ]]\n"
     ]
    }
   ],
   "source": [
    "print(t.texts_to_matrix(texts, mode = 'tfidf').round(2)) # 둘째 자리까지 반올림하여 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'tfidf' 모드는 말 그대로 TF-IDF 행렬을 만듭니다. 다만, TF-IDF 챕터에서 배운 기본식이나 사이킷런의 TfidfVectorizer에서 사용하는 식이랑 또 조금 다릅니다. 앞서 배운 기본식에서 TF는 각 문서에서의 각 단어의 빈도였다면 'tfidf' 모드에서는 TF를 각 문서에서의 각 단어의 빈도에 자연 로그를 씌우고 1을 더한 값으로 정의했습니다. idf에서는 앞서 배운 기본식에서 로그는 자연 로그를 사용하고, 로그 안의 분수에 1을 추가로 더했습니다. 물론, 이러한 식을 굳이 기억할 필요는 없고 여전히 TF-IDF의 기존 의도를 갖고 있다고 이해하면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.   0.   0.33 0.33 0.33 0.   0.   0.   0.   0.  ]\n",
      " [0.   0.33 0.33 0.33 0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.5  0.   0.   0.   0.25 0.25 0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.33 0.33 0.33]]\n"
     ]
    }
   ],
   "source": [
    "print(t.texts_to_matrix(texts, mode = 'freq').round(2)) # 둘째 자리까지 반올림하여 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "마지막으로 'freq' 모드입니다. 'freq' 모드는 각 문서에서의 각 단어의 등장 횟수를 분자로, 각 문서의 크기(각 문서에서 등장한 모든 단어의 개수의 총 합)를 분모로 하는 표현 방법입니다. 예를 들어 세번째 행을 보겠습니다. 세번째 문장은 '길고 노란 바나나 바나나' 였습니다. 문서의 크기는 4인데, 바나나는 총 2회 등장했습니다. 이에 따라서 세번째 문장에서의 단어 '바나나'의 값은 위의 행렬에서 0.5가 됩니다. 반면에 '길고', '노란'이라는 두 단어는 각 1회 등장했으므로 각자 1/4의 값인 0.25의 값을 가집니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 20개 뉴스 그룹(Twenty Newsgroups) 데이터에 대한 이해"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사이킷런에서는 20개의 다른 주제를 가진 18,846개의 뉴스 그룹 이메일 데이터를 제공합니다. (LSA 챕터와 동일한 데이터.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 20news dataset. This may take a few minutes.\n",
      "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
     ]
    }
   ],
   "source": [
    "newsdata = fetch_20newsgroups(subset = 'train') # 'train'을 기재하면 훈련 데이터만 리턴한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 subset의 값으로 'all'을 넣으면 전체 데이터인 18,846개의 샘플을 다운로드할 수 있으며, 'train'을 넣으면 훈련 데이터를, 'test'를 넣으면 테스트 데이터를 다운로드할 수 있습니다. newsdata.keys()를 출력하면 해당 데이터의 속성을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])\n"
     ]
    }
   ],
   "source": [
    "print(newsdata.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "해당 데이터는 data, filenames, target_names, target, DESCR, description이라는 6개 속성을 갖고 있습니다. 이 중 실제로 훈련에 사용할 속성은 이메일 본문인 data와 메일이 어떤 주제인지 기재된 숫자 레이블인 target입니다. 우선 훈련용 샘플의 개수를 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련용 샘플의 개수 : 11314\n"
     ]
    }
   ],
   "source": [
    "print('훈련용 샘플의 개수 : {}'.format(len(newsdata.data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련 샘플은 11,314개가 존재합니다. target_names에는 20개의 주제의 이름을 담고있습니다. 어떤 주제가 있는지 확인해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 주제의 개수 : 20\n",
      "['alt.atheism', 'comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'comp.windows.x', 'misc.forsale', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey', 'sci.crypt', 'sci.electronics', 'sci.med', 'sci.space', 'soc.religion.christian', 'talk.politics.guns', 'talk.politics.mideast', 'talk.politics.misc', 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "print('총 주제의 개수 : {}'.format(len(newsdata.target_names)))\n",
    "print(newsdata.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이번 챕터 실습의 목적은 테스트 데이터에서 이메일 본문을 보고 20개의 주제 중 어떤 주제인지를 맞추는 것입니다. 레이블인 target에는 총 0부터 19까지의 숫자가 들어가있는데 첫번째 샘플의 경우에는 몇 번 주제인지 확인해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "첫번째 샘플의 레이블 : 7\n"
     ]
    }
   ],
   "source": [
    "print('첫번째 샘플의 레이블 : {}'.format(newsdata.target[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "첫번째 샘플의 레이블의 값은 7입니다. 숫자만으로는 앞서 target_names를 통해 확인한 20개의 주제 중에서 어떤 주제를 의미하는지 알 수가 없습니다. 7이 실제로 어떤 주제를 나타내는지는 target_names[] 안에 숫자를 입력하여 알 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7번 레이블이 의미하는 주제 : rec.autos\n"
     ]
    }
   ],
   "source": [
    "print('7번 레이블이 의미하는 주제 : {}'.format(newsdata.target_names[7]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7번 레이블은 rec.autos라는 주제입니다. 즉, 첫번째 샘플의 주제는 rec.autos입니다. 첫번째 샘플의 본문 내용을 확인해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: lerxst@wam.umd.edu (where's my thing)\n",
      "Subject: WHAT car is this!?\n",
      "Nntp-Posting-Host: rac3.wam.umd.edu\n",
      "Organization: University of Maryland, College Park\n",
      "Lines: 15\n",
      "\n",
      " I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
      "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
      "the front bumper was separate from the rest of the body. This is \n",
      "all I know. If anyone can tellme a model name, engine specs, years\n",
      "of production, where this car is made, history, or whatever info you\n",
      "have on this funky looking car, please e-mail.\n",
      "\n",
      "Thanks,\n",
      "- IL\n",
      "   ---- brought to you by your neighborhood Lerxst ----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(newsdata.data[0]) # 첫번째 샘플 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이메일의 내용을 보니 스포츠 카에 대한 글로 보입니다. 이 글의 레이블은 7이고, 7번 레이블은 rec.autos란 주제를 의미합니다. 이제 훈련에 사용될 메일 본문인 data와 레이블인 target을 데이터프레임으로 만들어서 데이터에 대한 통계적인 정보들을 알아보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From: lerxst@wam.umd.edu (where's my thing)\\nS...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From: guykuo@carson.u.washington.edu (Guy Kuo)...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From: twillis@ec.ecn.purdue.edu (Thomas E Will...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From: jgreen@amber (Joe Green)\\nSubject: Re: W...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From: jcm@head-cfa.harvard.edu (Jonathan McDow...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               email  target\n",
       "0  From: lerxst@wam.umd.edu (where's my thing)\\nS...       7\n",
       "1  From: guykuo@carson.u.washington.edu (Guy Kuo)...       4\n",
       "2  From: twillis@ec.ecn.purdue.edu (Thomas E Will...       4\n",
       "3  From: jgreen@amber (Joe Green)\\nSubject: Re: W...       1\n",
       "4  From: jcm@head-cfa.harvard.edu (Jonathan McDow...      14"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(newsdata.data, columns = ['email']) # data로부터 데이터프레임 생성\n",
    "data['target'] = pd.Series(newsdata.target) # target 열 추가\n",
    "data[:5] # 상위 5개 행을 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "메일 본문에 해당하는 email열과 레이블에 해당되는 target 열, 2개의 열로 구성된 데이터프레임이 생성된 것을 볼 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11314 entries, 0 to 11313\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   email   11314 non-null  object\n",
      " 1   target  11314 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 176.9+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "news열은 문자열, target열은 정수형 데이터입니다. 혹시 Null 값을 가진 샘플이 있는지 isnull().values.any()로도 확인 가능합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "False는 데이터에 별도의 Null 값은 없음을 의미합니다. nunique()를 통해 샘플 중 중복을 제거한 개수를 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "중복을 제외한 샘플의 수 : 11314\n",
      "중복을 제외한 주제의 수 : 20\n"
     ]
    }
   ],
   "source": [
    "print('중복을 제외한 샘플의 수 : {}'.format(data['email'].nunique()))\n",
    "print('중복을 제외한 주제의 수 : {}'.format(data['target'].nunique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 레이블 값의 분포를 시각화해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['target'].value_counts().plot(kind='bar');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10번 레이블의 수가 가장 많고, 19번 레이블의 수가 가장 적으며 대체적으로 400 ~ 600개 사이의 분포를 보입니다. 이번에는 각 레이블이 몇 개 있는지 구체적인 수치로 확인해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    target  count\n",
      "0        0    480\n",
      "1        1    584\n",
      "2        2    591\n",
      "3        3    590\n",
      "4        4    578\n",
      "5        5    593\n",
      "6        6    585\n",
      "7        7    594\n",
      "8        8    598\n",
      "9        9    597\n",
      "10      10    600\n",
      "11      11    595\n",
      "12      12    591\n",
      "13      13    594\n",
      "14      14    593\n",
      "15      15    599\n",
      "16      16    546\n",
      "17      17    564\n",
      "18      18    465\n",
      "19      19    377\n"
     ]
    }
   ],
   "source": [
    "print(data.groupby('target').size().reset_index(name='count'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 데이터프레임으로부터 다시 메일 본문과 레이블을 분리하고, 테스트 데이터 또한 불러오겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsdata_test = fetch_20newsgroups(subset='test', shuffle=True) # 'test'를 기재하면 테스트 데이터만 리턴한다.\n",
    "train_email = data['email'] # 훈련 데이터의 본문 저장\n",
    "train_label = data['target'] # 훈련 데이터의 레이블 저장\n",
    "test_email = newsdata_test.data # 테스트 데이터의 본문 저장\n",
    "test_label = newsdata_test.target # 테스트 데이터의 레이블 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련 데이터와 테스트 데이터가 모두 준비되었습니다. 케라스의 토크나이저 도구를 사용하여 전처리를 진행해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 10000 # 실습에 사용할 단어의 최대 개수\n",
    "num_classes = 20 # 레이블의 수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우선 필요한 변수들을 정의합니다. max_words는 이번 실습에서 사용할 최대 단어 개수를 정의하는 변수입니다. 뒤에서 케라스 토크나이저를 사용하면 빈도수 순으로 인덱스를 부여하므로, 빈도수가 가장 높은 상위 max_words 개수만큼의 단어를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(train_data, test_data, mode): # 전처리 함수\n",
    "    t = Tokenizer(num_words = max_words) # max_words 개수만큼의 단어만 사용한다.\n",
    "    t.fit_on_texts(train_data)\n",
    "    X_train = t.texts_to_matrix(train_data, mode=mode) # 샘플 수 × max_words 크기의 행렬 생성\n",
    "    X_test = t.texts_to_matrix(test_data, mode=mode) # 샘플 수 × max_words 크기의 행렬 생성\n",
    "    return X_train, X_test, t.index_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "케라스 토크나이저로 전처리를 수행하는 함수인 prepare_data를 만들었습니다. 해당 함수는 케라스 토크나이저를 통해 단어 토큰화를 수행하고, 앞서 배운 texts_to_matrix()를 사용하여 훈련 데이터와 테스트 데이터를 'binary', 'count', 'tfidf', 'freq' 4개의 모드 중 사용자가 정한 모드로 변환합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, index_to_word = prepare_data(train_email, test_email, 'binary') # binary 모드로 변환\n",
    "y_train = to_categorical(train_label, num_classes) # 원-핫 인코딩\n",
    "y_test = to_categorical(test_label, num_classes) # 원-핫 인코딩"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "메일 본문에 대해서는 'binary' 모드로 변환하고, 훈련 데이터와 테스트 데이터의 레이블은 원-핫 인코딩을 수행하였습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 샘플 본문의 크기 : (11314, 10000)\n",
      "훈련 샘플 레이블의 크기 : (11314, 20)\n",
      "테스트 샘플 본문의 크기 : (7532, 10000)\n",
      "테스트 샘플 레이블의 크기 : (7532, 20)\n"
     ]
    }
   ],
   "source": [
    "print('훈련 샘플 본문의 크기 : {}'.format(X_train.shape))\n",
    "print('훈련 샘플 레이블의 크기 : {}'.format(y_train.shape))\n",
    "print('테스트 샘플 본문의 크기 : {}'.format(X_test.shape))\n",
    "print('테스트 샘플 레이블의 크기 : {}'.format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련 데이터와 테스트 데이터 모두 메일 본문의 크기가 샘플의 수 × 10,000의 행렬로 변환되었는데, 열의 개수가 10,000인 것은 위의 prepard_data 함수 내부에서 Tokenizer의 num_words의 인자로 max_words를 지정해주었기 때문입니다. 사실 단어의 정수 인덱스는 1부터 시작하지만, 행렬의 인덱스는 0부터 시작하여 0번 인덱스는 사용되지 않으므로 실제로 행렬에는 빈도수 기준 상위 9,999개의 단어가 표현된 셈입니다. 빈도수 상위 1번 단어와 9,999번 단어를 확인해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "빈도수 상위 1번 단어 : the\n",
      "빈도수 상위 9999번 단어 : mic\n"
     ]
    }
   ],
   "source": [
    "print('빈도수 상위 1번 단어 : {}'.format(index_to_word[1]))\n",
    "print('빈도수 상위 9999번 단어 : {}'.format(index_to_word[9999]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "불용어에 해당되는 단어 'the'가 빈도수 상위 1번 단어가 된 것을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 다층 퍼셉트론(Multilayer Perceptron, MLP)을 사용하여 텍스트 분류하기\n",
    "\n",
    "이제 모델을 설계해보겠습니다. 우선 모델 설계에 필요한 도구들을 임포트합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다층 퍼셉트론을 설계합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_evaluate(X_train, y_train, X_test, y_test):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, input_shape=(max_words,), activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, batch_size=128, epochs=5, verbose=1, validation_split=0.1)\n",
    "    score = model.evaluate(X_test, y_test, batch_size=128, verbose=0)\n",
    "    return score[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델 설계를 fit_and_evaluate라는 함수 내에 정의하였는데, 모델을 함수 내에 정의한 이유는 이번 실습에서는 입력값을 바꿔가면서 모델을 여러번 호출하기 위함입니다. 우선은 모델의 아키텍처에 집중해보겠습니다.\n",
    "\n",
    "![Alt text]( multilayerperceptron.png )\n",
    "\n",
    "위의 그림은 현재 설계한 신경망의 구조를 보여줍니다. 현재 설계한 다층 퍼셉트론은 총 4개의 층을 가지고 있습니다. max_words의 크기를 가진 입력층, 256개의 뉴런을 가진 첫번째 은닉층, 128개의 뉴런을 가진 두번째 은닉층, num_classes의 크기를 가진 출력층입니다. 또한 이번에 설계한 다층 퍼셉트론은 은닉층이 2개이므로 깊은 신경망(Deep Neural Network, DNN)입니다.\n",
    "\n",
    "코드로 돌아가보겠습니다. 위 모델에서는 과적합을 막기 위해서 두 번의 드롭아웃(Dropout)을 적용하였습니다. 이 문제는 다중 클래스 분류 문제입니다. 여러 개의 선택지 중에서 하나의 선택지를 고르는 문제인데, 이 경우 20개의 주제 중에서 모델은 자신이 정답이라고 생각하는 1개의 주제를 예측해야 합니다. 다중 클래스 분류 문제이므로 출력층의 활성화 함수로는 소프트맥스 함수를 사용하고, 손실 함수로는 크로스 엔트로피(categorical_crossentropy) 함수를 사용하였습니다.\n",
    "\n",
    "모델을 훈련시켜보겠습니다. 이번에는 앞서 배운 texts_to_matrix()의 4개의 모드에 대해서 전부 모델의 결과를 확인해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10182 samples, validate on 1132 samples\n",
      "Epoch 1/5\n",
      "10182/10182 [==============================] - 3s 283us/sample - loss: 2.2784 - accuracy: 0.3375 - val_loss: 0.9487 - val_accuracy: 0.8242\n",
      "Epoch 2/5\n",
      "10182/10182 [==============================] - 2s 186us/sample - loss: 0.8610 - accuracy: 0.7652 - val_loss: 0.4791 - val_accuracy: 0.8772\n",
      "Epoch 3/5\n",
      "10182/10182 [==============================] - 2s 188us/sample - loss: 0.4309 - accuracy: 0.8898 - val_loss: 0.3456 - val_accuracy: 0.9108\n",
      "Epoch 4/5\n",
      "10182/10182 [==============================] - 2s 200us/sample - loss: 0.2657 - accuracy: 0.9304 - val_loss: 0.3112 - val_accuracy: 0.9161\n",
      "Epoch 5/5\n",
      "10182/10182 [==============================] - 2s 209us/sample - loss: 0.1786 - accuracy: 0.9573 - val_loss: 0.2877 - val_accuracy: 0.9152\n",
      "binary 모드의 테스트 정확도: 0.8307223\n",
      "Train on 10182 samples, validate on 1132 samples\n",
      "Epoch 1/5\n",
      "10182/10182 [==============================] - 3s 275us/sample - loss: 2.7537 - accuracy: 0.2486 - val_loss: 1.6366 - val_accuracy: 0.7058\n",
      "Epoch 2/5\n",
      "10182/10182 [==============================] - 2s 199us/sample - loss: 1.4563 - accuracy: 0.6352 - val_loss: 0.7173 - val_accuracy: 0.8489\n",
      "Epoch 3/5\n",
      "10182/10182 [==============================] - 2s 202us/sample - loss: 0.7837 - accuracy: 0.8073 - val_loss: 0.4851 - val_accuracy: 0.8781\n",
      "Epoch 4/5\n",
      "10182/10182 [==============================] - 2s 204us/sample - loss: 0.5432 - accuracy: 0.8713 - val_loss: 0.4193 - val_accuracy: 0.8896\n",
      "Epoch 5/5\n",
      "10182/10182 [==============================] - 2s 216us/sample - loss: 0.4047 - accuracy: 0.9125 - val_loss: 0.3752 - val_accuracy: 0.8975\n",
      "count 모드의 테스트 정확도: 0.8240839\n",
      "Train on 10182 samples, validate on 1132 samples\n",
      "Epoch 1/5\n",
      "10182/10182 [==============================] - 3s 277us/sample - loss: 2.2149 - accuracy: 0.3682 - val_loss: 0.7647 - val_accuracy: 0.8481\n",
      "Epoch 2/5\n",
      "10182/10182 [==============================] - 2s 201us/sample - loss: 0.8219 - accuracy: 0.7749 - val_loss: 0.4314 - val_accuracy: 0.8905\n",
      "Epoch 3/5\n",
      "10182/10182 [==============================] - 2s 207us/sample - loss: 0.4279 - accuracy: 0.8886 - val_loss: 0.3672 - val_accuracy: 0.9064\n",
      "Epoch 4/5\n",
      "10182/10182 [==============================] - 2s 209us/sample - loss: 0.2762 - accuracy: 0.9286 - val_loss: 0.3160 - val_accuracy: 0.9117\n",
      "Epoch 5/5\n",
      "10182/10182 [==============================] - 2s 233us/sample - loss: 0.1936 - accuracy: 0.9494 - val_loss: 0.3188 - val_accuracy: 0.9187\n",
      "tfidf 모드의 테스트 정확도: 0.82992566\n",
      "Train on 10182 samples, validate on 1132 samples\n",
      "Epoch 1/5\n",
      "10182/10182 [==============================] - 3s 277us/sample - loss: 2.9802 - accuracy: 0.0870 - val_loss: 2.9387 - val_accuracy: 0.2306\n",
      "Epoch 2/5\n",
      "10182/10182 [==============================] - 2s 192us/sample - loss: 2.7689 - accuracy: 0.1958 - val_loss: 2.4685 - val_accuracy: 0.3065\n",
      "Epoch 3/5\n",
      "10182/10182 [==============================] - 2s 197us/sample - loss: 2.2613 - accuracy: 0.3092 - val_loss: 1.9438 - val_accuracy: 0.4956\n",
      "Epoch 4/5\n",
      "10182/10182 [==============================] - 2s 225us/sample - loss: 1.8175 - accuracy: 0.4378 - val_loss: 1.5499 - val_accuracy: 0.6705\n",
      "Epoch 5/5\n",
      "10182/10182 [==============================] - 2s 236us/sample - loss: 1.4544 - accuracy: 0.5629 - val_loss: 1.2255 - val_accuracy: 0.7102\n",
      "freq 모드의 테스트 정확도: 0.66529477\n"
     ]
    }
   ],
   "source": [
    "modes = ['binary', 'count', 'tfidf', 'freq'] # 4개의 모드를 리스트에 저장.\n",
    "\n",
    "for mode in modes: # 4개의 모드에 대해서 각각 아래의 작업을 반복한다.\n",
    "    X_train, X_test, _ = prepare_data(train_email, test_email, mode) # 모드에 따라서 데이터를 전처리\n",
    "    score = fit_and_evaluate(X_train, y_train, X_test, y_test) # 모델을 훈련하고 평가.\n",
    "    print(mode+' 모드의 테스트 정확도:', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 모드에 대해서 총 5회의 에포크를 수행하는데, 각 모드에 대한 정확도는 다음과 같이 나왔습니다.\n",
    "\n",
    "대체적으로 82% ~ 83%의 비슷한 정확도를 보이는데, 'freq' 모드에서만 정확도가 69%가 나왔습니다. 아무래도 'freq' 모드는 이번 문제를 풀기위한 적절한 전처리 방법이 아니었던 것 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
