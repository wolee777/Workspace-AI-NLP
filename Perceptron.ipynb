{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 퍼셉트론( Perceptron )\n",
    "\n",
    "## 1. 퍼셉트론( Perceptron )\n",
    "\n",
    "- 퍼셉트론(Perceptron)은 프랑크 로젠블라트(Frank Rosenblatt)가 1957년에 제안한 초기 형태의 인공 신경망으로 다수의 입력으로부터 하나의 결과를 내보내는 알고리즘입니다. \n",
    "- 퍼셉트론은 실제 뇌를 구성하는 신경 세포 뉴런의 동작과 유사한데, 신경 세포 뉴런의 그림을 먼저 보도록 하겠습니다. \n",
    "- 뉴런은 가지돌기에서 신호를 받아들이고, 이 신호가 일정치 이상의 크기를 가지면 축삭돌기를 통해서 신호를 전달합니다.\n",
    "\n",
    "![Alt text]( neuron.png )\n",
    "\n",
    "- 이제 다수의 입력을 받는 퍼셉트론의 그림을 보겠습니다. \n",
    "- 신경 세포 뉴런의 입력 신호와 출력 신호가 퍼셉트론에서 각각 입력값과 출력값에 해당됩니다.\n",
    "\n",
    "![Alt text]( perceptrin1_final.png )\n",
    "\n",
    "- ***x는 입력값을 의미하며, W는 가중치(Weight), y는 출력값***입니다. \n",
    "- 그림 안의 원은 인공 뉴런에 해당됩니다. \n",
    "- 실제 신경 세포 뉴런에서의 신호를 전달하는 ***축삭돌기의 역할을 퍼셉트론에서는 가중치가 대신***합니다. \n",
    "- ***각각의 인공 뉴런에서 보내진 입력값 x는 각각의 가중치 W와 함께 종착지인 인공 뉴런에 전달***되고 있습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 각각의 입력값에는 각각의 가중치가 존재하는데, 이때 ***가중치의 값이 크면 클수록 해당 입력 값이 중요하다는 것***을 의미합니다.   \n",
    "- ***각 입력값이 가중치와 곱해져서 인공 뉴런에 보내지고, 각 입력값과 그에 해당되는 가중치의 곱의 전체 합이 임계치(threshold)를 넘으면 종착지에 있는 인공 뉴런은 출력 신호로서 1을 출력하고, 그렇지 않을 경우에는 0을 출력***합니다. \n",
    "- 이러한 함수를 ***계단 함수(Step function)***라고 하며, 아래는 그래프는 계단 함수의 하나의 예를 보여줍니다.\n",
    "\n",
    "![Alt text]( step_function.png )\n",
    "\n",
    "- 이때 계단 함수에 사용된 이 임계치값을 수식으로 표현할 때는 보통 세타(Θ)로 표현합니다. 이를 식으로 표현하면 다음과 같습니다.\n",
    "\n",
    "if n sigma i Wixi >= Θ -> y = 1\n",
    "\n",
    "if n sigma i wixi < Θ -> y = 0\n",
    "\n",
    "- 단, 위의 식에서 임계치를 좌변으로 넘기고 편향 b(bias)로 표현할 수도 있습니다. ***편향 b 또한 퍼셉트론의 입력***으로 사용됩니다. 보통 그림으로 표현할 때는 입력값이 1로 고정되고 편향 b가 곱해지는 변수로 표현됩니다.\n",
    "\n",
    "![Alt text]( perceptron2_final.png )\n",
    "\n",
    "if n sigma i Wixi + b >= Θ -> y = 1\n",
    "\n",
    "if n sigma i wixi + b < Θ -> y = 0\n",
    "\n",
    "- 보통 설명을 할 때 편의상 편향 b가 생략되서어 표현되기도 하지만 실제로 편향 b 또한 딥 러닝이 최적의 값을 찾아야 할 변수 중 하나입니다.\n",
    "\n",
    "- 뉴런에서 출력값을 변경시키는 함수를 ***활성화 함수(Activation Function)***라고 합니다. \n",
    "- 초기 인공 신경망 모델인 퍼셉트론은 ***활성화 함수로 계단 함수***를 사용하였지만, 그 뒤에 등장한 여러가지 발전된 신경망들은 계단 함수 외에도 여러 다양한 활성화 함수를 사용하기 시작했습니다. \n",
    "- ***시그모이드 함수나 소프트맥스 함수 또한 활성화 함수 중 하나***입니다.\n",
    "\n",
    "- 퍼셉트론의 활성화 함수는 계단 함수이지만 여기서 활성화 함수를 시그모이드 함수로 변경하면 퍼셉트론은 곧 이진 분류를 수행하는 로지스틱 회귀와 동일함을 알 수 있습니다.\n",
    "\n",
    "- 로지스틱 회귀 모델이 인공 신경망에서는 하나의 인공 뉴런으로 볼 수 있습니다. 로지스틱 회귀를 수행하는 인공 뉴런과 퍼셉트론의 차이는 오직 활성화 함수의 차이입니다.\n",
    "\n",
    "- 인공 뉴런 : 활성화 함수 f(∑niWixi+b)\n",
    "- 위의 퍼셉트론(인공 뉴런 종류 중 하나) : 계단 함수 f(∑niWixi+b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 단층 퍼셉트롤( Single-Layer Perceptron )\n",
    "\n",
    "- 퍼셉트론은 단층 퍼셉트론과 다층 퍼셉트론으로 나누어지는데, 단층 퍼셉트론은 값을 보내는 단계과 값을 받아서 출력하는 두 단계로만 이루어집니다. 이때 이 각 단계를 보통 층(layer)라고 부르며, 이 두 개의 층을 입력층(input layer)과 출력층(output layer)이라고 합니다.\n",
    "\n",
    "![Alt text]( perceptron3_final.png )\n",
    "\n",
    "- 단층 퍼셉트론을 이용하면 AND, NAND, OR 게이트를 쉽게 구현할 수 있습니다. \n",
    "- 게이트 연산에 쓰이는 것은 두 개의 입력값과 하나의 출력값입니다. 예를 들어 AND 게이트의 경우에는 두 개의 입력 값이 모두 1인 경우에만 출력값이 1이 나오는 구조를 갖고 있습니다.\n",
    "\n",
    "|x1|x2|y|\n",
    "|---|---|---|\n",
    "|0|0|0|\n",
    "|0|1|0|\n",
    "|1|0|0|\n",
    "|1|1|1|\n",
    "\n",
    "- 단층 퍼셉트론의 식을 통해 AND 게이트를 만족하는 두 개의 가중치와 편향 값에는 뭐가 있을까요? \n",
    "- 각각 w1, w2, b라고 한다면 [0.5, 0.5, -0.7], [0.5, 0.5, -0.8] 또는 [1.0, 1.0, -1.0] 등 이 외에도 다양한 가중치와 편향의 조합이 나올 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AND_gate( x1, x2 ):\n",
    "    w1 = 0.5\n",
    "    w2 = 0.5\n",
    "    b = -0.7\n",
    "    result = x1 * w1 + x2 * w2 + b\n",
    "    \n",
    "    if result <= 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0, 0, 1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AND_gate( 0, 0 ), AND_gate( 0, 1 ), AND_gate( 1, 0 ), AND_gate( 1, 1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 두 개의 입력값이 1인 경우에만 출력값이 0, 나머지 입력값의 쌍(pair)에 대해서는 모두 출력값이 1이 나오는 NAND 게이트는 어떨까요?\n",
    "\n",
    "|x1|x2|y|\n",
    "|---|---|---|\n",
    "|0|0|1|\n",
    "|0|1|1|\n",
    "|1|0|1|\n",
    "|1|1|0|\n",
    "\n",
    "- AND 게이트를 충족하는 가중치와 편향값인 [0.5, 0.5, -0.7]에 -를 붙여서 [-0.5, -0.5, +0.7]을 단층 퍼셉트론의 식에 넣어보면 NAND 게이트를 충족합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NAND_gate( x1, x2 ):\n",
    "    w1 = -0.5\n",
    "    w2 = -0.5\n",
    "    b = 0.7\n",
    "    result = x1 * w1 + x2 * w2 + b\n",
    "    \n",
    "    if result <= 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 1, 0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NAND_gate( 0, 0 ), NAND_gate( 0, 1 ), NAND_gate( 1, 0 ), NAND_gate( 1, 1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- NAND 게이트를 구현한 파이썬 코드에 입력값을 넣자, 두 개의 입력값이 1인 경우에만 0이 나오는 것을 확인할 수 있습니다. 퍼셉트론으로 NAND 게이트를 구현한 것입니다.  \n",
    "- [-0.5, -0.5, -0.7] 외에도 퍼셉트론이 NAND 게이트의 동작을 하도록 하는 다양한 가중치와 편향의 값들이 있을 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 두 개의 입력이 모두 0인 경우에 출력값이 0이고 나머지 경우에는 모두 출력값이 1인 OR 게이트 또한 적절한 가중치 값과 편향 값만 찾으면 단층 퍼셉트론의 식으로 구현할 수 있습니다.\n",
    "\n",
    "|x1|x2|y|\n",
    "|---|---|---|\n",
    "|0|0|0|\n",
    "|0|1|1|\n",
    "|1|0|1|\n",
    "|1|1|1|\n",
    "\n",
    "- 각 가중치와 편향에 대해서 [0.6, 0.6, -0.5]를 선택하면 OR 게이트를 충족합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OR_gate( x1, x2 ):\n",
    "    w1 = 0.6\n",
    "    w2 = 0.6\n",
    "    b = -0.5\n",
    "    result = x1 * w1 + x2 * w2 + b\n",
    "    \n",
    "    if result <= 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1, 1, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OR_gate( 0, 0 ), OR_gate( 0, 1 ), OR_gate( 1, 0 ), OR_gate( 1, 1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 물론, 이 외에도 이를 충족하는 다양한 가중치와 편향의 값이 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이처럼 단층 퍼셉트론은 AND 게이트, NAND 게이트, OR 게이트 또한 구현할 수 있습니다. \n",
    "- 하지만 단층 퍼셉트론으로 구현이 불가능한 게이트가 있는데 바로 XOR 게이트입니다. \n",
    "- XOR 게이트는 입력값 두 개가 서로 다른 값을 갖고 있을때에만 출력값이 1이 되고, 입력값 두 개가 서로 같은 값을 가지면 출력값이 0이 되는 게이트입니다. \n",
    "- 위의 파이썬 코드에 아무리 수많은 가중치와 편향을 넣어봐도 XOR 게이트를 구현하는 것은 불가능합니다. \n",
    "- 그 이유는 단층 퍼셉트론은 직선 하나로 두 영역을 나눌 수 있는 문제에 대해서만 구현이 가능하기 때문입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- AND 게이트에 대한 단층 퍼셉트론을 시각화해보면 다음과 같습니다.\n",
    "\n",
    "![Alt text]( andgraphgate.png )\n",
    "\n",
    "- 그림에서는 출력값 0을 하얀색 원, 1을 검은색 원으로 표현했습니다. \n",
    "- AND 게이트를 충족하려면 하얀색 원과 검은색 원을 직선으로 나누게 됩니다. \n",
    "- 마찬가지로 NAND 게이트나 OR 게이트에 대해서도 시각화를 했을 때 직선으로 나누는 것이 가능합니다.\n",
    "\n",
    "![Alt text]( oragateandnandgate.png )\n",
    "\n",
    "- 그렇다면 XOR 게이트는 어떨까요? XOR 게이트는 입력값 두 개가 서로 다른 값을 갖고 있을때에만 출력값이 1이 되고, 입력값 두 개가 서로 같은 값을 가지면 출력값이 0이 되는 게이트입니다. XOR 게이트를 시각화해보면 다음과 같습니다.\n",
    "\n",
    "![Alt text]( xorgraphandxorgate.png )\n",
    "\n",
    "- 하얀색 원과 검은색 원을 직선 하나로 나누는 것은 불가능합니다. \n",
    "- 즉, 단층 퍼셉트론으로는 XOR 게이트를 구현하는 것이 불가능합니다. \n",
    "- 이를 단층 퍼셉트론은 선형 영역에 대해서만 분리가 가능하다고 말합니다. \n",
    "- 다시 말하면 XOR 게이트는 직선이 아닌 곡선. 비선형 영역으로 분리하면 구현이 가능합니다.\n",
    "\n",
    "![Alt text]( xorgate_nonlinearity.png )\n",
    "\n",
    "- 위의 그림은 곡선을 사용한다면 하얀색 원과 검은색 원을 나눌 수 있음을 보여줍니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 다층 퍼셉트론( MultiLayer Perceptron, MLP )\n",
    "\n",
    "- XOR 게이트는 기존의 AND, NAND, OR 게이트를 조합하면 만들 수 있습니다. \n",
    "- 퍼셉트론 관점에서 말하면, 층을 더 쌓으면 만들 수 있습니다. \n",
    "- 다층 퍼셉트론과 단층 퍼셉트론의 차이는 단층 퍼셉트론은 입력층과 출력층만 존재하지만, 다층 퍼셉트론은 중간에 층을 더 추가하였다는 점입니다. \n",
    "- 이렇게 입력층과 출력층 사이에 존재하는 층을 은닉층(hidden layer)이라고 합니다. \n",
    "- 즉, 다층 퍼셉트론은 중간에 은닉층이 존재한다는 점이 단층 퍼셉트론과 다릅니다. 다층 퍼셉트론은 줄여서 MLP라고도 부릅니다.\n",
    "\n",
    "![Alt text]( perceptron_4image.jpg )\n",
    "\n",
    "- 위의 그림은 AND, NAND, OR 게이트를 조합하여 XOR 게이트를 구현한 다층 퍼셉트론의 예입니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def XOR_gate( x1, x2 ):\n",
    "    s1 = NAND_gate( x1, x2 )\n",
    "    s2 = OR_gate( x1, x2 )\n",
    "    y = AND_gate( s1, s2 )\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1, 1, 0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XOR_gate( 0, 0 ), XOR_gate( 0, 1 ), XOR_gate( 1, 0 ), XOR_gate( 1, 1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- XOR 예제에서는 은닉층 1개만으로 문제를 해결할 수 있었지만, 다층 퍼셉트론은 본래 은닉층이 1개 이상인 퍼셉트론을 말합니다. \n",
    "- 즉, XOR 문제보다 더욱 복잡한 문제를 해결하기 위해서 다층 퍼셉트론은 중간에 수많은 은닉층을 더 추가할 수 있습니다. \n",
    "- 은닉층의 개수는 2개일 수도 있고, 수십 개일수도 있고 사용자가 설정하기 나름입니다. \n",
    "- 아래는 더 어려운 문제를 풀기 위해서 은닉층이 하나 더 추가되고(이 경우에는 은닉층이 2개), 뉴런의 개수를 늘린 다층 퍼셉트론의 모습을 보여줍니다.\n",
    "\n",
    "![Alt text]( multilayer_perceptron.png )\n",
    "\n",
    "- 은닉층이 2개 이상인 신경망을 심층 신경망(Deep Neural Network, DNN)이라고 합니다. \n",
    "- 심층 신경망은 다층 퍼셉트론만 이야기 하는 것이 아니라, 여러 변형된 다양한 신경망들도 은닉층이 2개 이상이 되면 심층 신경망이라고 합니다.\n",
    "\n",
    "- 지금까지 OR, AND, XOR 게이트 등. 퍼셉트론이 가야할 정답을 참고로 퍼셉트론이 정답을 출력할 때까지 가중치를 바꿔보면서 맞는 가중치를 찾았습니다. \n",
    "- 즉, 가중치를 수동으로 찾았습니다. \n",
    "- 하지만 이제는 기계가 가중치를 스스로 찾아내도록 자동화시켜야하는데, 이것이 머신 러닝에서 말하는 학습(training) 단계에 해당됩니다. \n",
    "- 앞서 선형 회귀와 로지스틱 회귀에서 보았듯이 손실 함수(Loss function)와 옵티마이저(Optimizer)를 사용합니다.\n",
    "- 그리고 만약 학습을 시키는 인공 신경망이 심층 신경망일 경우에는 이를 심층 신경망을 학습시킨다고 하여, 딥 러닝(Deep Learning)이라고 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
