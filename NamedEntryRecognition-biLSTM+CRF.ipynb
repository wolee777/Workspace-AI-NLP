{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 양방향  LSTM +  CRF 이용 개체명 인식"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  CRF layer 사용을 위한 환경구성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tensorflow 1.13.1 install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow==1.13.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### keras 2.2.4 install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install keras==2.2.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### keras contrib( CRF layer ) install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install git+https://www.github.com/keras-team/keras-contrib.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 개체명 인식을 위한 데이터 이해 및 전처리 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read.csv( 'ner_dataset.csv', encoding = 'latin1' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[ :5 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( '데이터프레임 행의 개수 : {}'.format( len( data ) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( '데이터에 null 값이 있는지 유무 : {}'.format( str( data.isnull().values.any() ) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( '어떤 열에 null 값이 있는지 출력' )\n",
    "print( '=================================' )\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( 'sentence # 열의 중복을 제거한 값의 개수 : {}'.format( data[ 'Sentence #' ].nunique() ) )\n",
    "print( 'Word 열의 중복을 제거한 값의 개수 : {}'.format( data.Word.nunique() ) )\n",
    "print( 'Tag 열의 중복을 제거한 값의 개수 : {}'.format( data.Tag.nunique() ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( 'Tag 열의 각각의 값의 개수 카운트' )\n",
    "print( '================================' )\n",
    "print( data.groupby( 'Tag' ).size().reset_index( name = 'count' ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.fillna( method = \"ffill\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( data.tail() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( '데이터에 Null 값이 있는지 유무 : ' + str( data.isnull().values.any() ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[ 'Word' ] = data[ 'Word' ].str.lower()\n",
    "print( 'Word 열의 중복을 제거한 값의 개수 : {}'.format( data.Word.nunique() ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( data[ :5 ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "func = lambda temp : [ ( w, t ) for w, t in zip( temp[ \"Word\" ].values.tolist(), temp[ \"Tag\" ].values.tolist() ) ]\n",
    "tagged_sentences = [ t for t in data.groupby( \"Sentence #\" ).apply( func ) ]\n",
    "print( \"전체 샘플 개수: {}\".format( len( tagged_sentences ) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( tagged_sentences[ 0 ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences, ner_tags = [], [] \n",
    "for tagged_sentence in tagged_sentences: # 47,959개의 문장 샘플을 1개씩 불러온다.\n",
    "    sentence, tag_info = zip( *tagged_sentence ) # 각 샘플에서 단어들은 sentence에 개체명 태깅 정보들은 tag_info에 저장.\n",
    "    sentences.append( list( sentence ) ) # 각 샘플에서 단어 정보만 저장한다.\n",
    "    ner_tags.append( list( tag_info ) ) # 각 샘플에서 개체명 태깅 정보만 저장한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( sentences[ 0 ] )\n",
    "print( ner_tags[ 0 ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( sentences[ 98 ] )\n",
    "print( ner_tags[ 98 ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( '샘플의 최대 길이 : %d' % max( len( l ) for l in sentences ) )\n",
    "print( '샘플의 평균 길이 : %f' % ( sum( map( len, sentences ) ) / len( sentences ) ) )\n",
    "plt.hist( [ len( s ) for s in sentences] , bins = 50 )\n",
    "plt.xlabel( 'length of samples' )\n",
    "plt.ylabel( 'number of samples' )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_tokenizer = Tokenizer( oov_token = 'OOV' ) # 모든 단어를 사용하지만 인덱스 1에는 단어 'OOV'를 할당한다.\n",
    "src_tokenizer.fit_on_texts( sentences )\n",
    "tar_tokenizer = Tokenizer( lower = False ) # 태깅 정보들은 내부적으로 대문자를 유지한채로 저장\n",
    "tar_tokenizer.fit_on_texts( ner_tags )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len( src_tokenizer.word_index ) + 1\n",
    "tag_size = len( tar_tokenizer.word_index ) + 1\n",
    "print( '단어 집합의 크기 : {}'.format( vocab_size ) )\n",
    "print( '개체명 태깅 정보 집합의 크기 : {}'.format( tag_size ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( '단어 OOV의 인덱스 : {}'.format( src_tokenizer.word_index[ 'OOV' ] ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = src_tokenizer.texts_to_sequences( sentences )\n",
    "y_train = tar_tokenizer.texts_to_sequences( ner_tags )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( X_train[ 0 ] )\n",
    "print( y_train[ 0 ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_to_word = src_tokenizer.index_word\n",
    "index_to_ner = tar_tokenizer.index_word\n",
    "index_to_ner[ 0 ] = 'PAD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( index_to_ner )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded = []\n",
    "for index in X_train[ 0 ] : # 첫번째 샘플 안의 인덱스들에 대해서\n",
    "    decoded.append( index_to_word[ index ] ) # 다시 단어로 변환\n",
    "\n",
    "print( '기존의 문장 : {}'.format( sentences[ 0 ] ) )\n",
    "print( '디코딩 문장 : {}'.format( decoded ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 70\n",
    "X_train = pad_sequences( X_train, padding = 'post', maxlen = max_len )\n",
    "# X_train의 모든 샘플들의 길이를 맞출 때 뒤의 공간에 숫자 0으로 채움.\n",
    "\n",
    "y_train = pad_sequences( y_train, padding = 'post', maxlen = max_len )\n",
    "# y_train의 모든 샘플들의 길이를 맞출 때 뒤의 공간에 숫자0으로 채움."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 훈련/테스트 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( X_train, y_train, test_size = .2, random_state = 777 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical( y_train, num_classes = tag_size )\n",
    "y_test = to_categorical( y_test, num_classes = tag_size )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( '훈련 샘플 문장의 크기 : {}'.format( X_train.shape ) )\n",
    "print( '훈련 샘플 레이블의 크기 : {}'.format( y_train.shape ) )\n",
    "print( '테스트 샘플 문장의 크기 : {}'.format( X_test.shape ) )\n",
    "print( '테스트 샘플 레이블의 크기 : {}'.format( y_test.shape ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 양방향 LSTM + CRF를 이용한 개체명 인식 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
    "from keras_contrib.layers import CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add( Embedding( input_dim = vocab_size, output_dim = 20, input_length = max_len, mask_zero = True ) )\n",
    "model.add( Bidirectional( LSTM( units = 50, return_sequences = True, recurrent_dropout = 0.1 ) ) )\n",
    "model.add( TimeDistributed( Dense( 50, activation = \"relu\" ) ) )\n",
    "crf = CRF( tag_size )\n",
    "model.add( crf )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile( optimizer = \"rmsprop\", loss = crf.loss_function, metrics = [ crf.accuracy ] )\n",
    "history = model.fit( X_train, y_train, batch_size = 32, epochs = 5, validation_split = 0.1, verbose = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( \"\\n 테스트 정확도: %.4f\" % ( model.evaluate( X_test, y_test )[ 1 ] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=13 # 확인하고 싶은 테스트용 샘플의 인덱스.\n",
    "y_predicted = model.predict( np.array( [ X_test[ i ] ] ) ) # 입력한 테스트용 샘플에 대해서 예측 y를 리턴\n",
    "y_predicted = np.argmax( y_predicted, axis = -1 ) # 원-핫 인코딩을 다시 정수 인코딩으로 변경함.\n",
    "true = np.argmax( y_test[ i ], -1 ) # 원-핫 인코딩을 다시 정수 인코딩으로 변경함.\n",
    "\n",
    "print( \"{:15}|{:5}|{}\".format( \"단어\", \"실제값\", \"예측값\" ) )\n",
    "print( 35 * \"-\")\n",
    "\n",
    "for w, t, pred in zip( X_test[ i ], true, y_predicted[ 0 ]) :\n",
    "    if w != 0: # PAD값은 제외함.\n",
    "        print( \"{:17}: {:7} {}\".format( index_to_word[ w ], index_to_ner[ t ], index_to_ner[ pred ] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = range( 1, len(history.history[ 'val_loss' ] ) + 1 )\n",
    "plt.plot( epochs, history.history[ 'loss' ] )\n",
    "plt.plot( epochs, history.history[ 'val_loss'] )\n",
    "plt.title( 'model loss' )\n",
    "plt.ylabel( 'loss' )\n",
    "plt.xlabel( 'epoch' )\n",
    "plt.legend( [ 'train', 'val' ], loc = 'upper left' )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### f1 score install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install seqeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqeval.metrics import precision_score, recall_score, f1_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 훈련된 모델  f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequences_to_tag( sequences ): # 예측값을 index_to_tag를 사용하여 태깅 정보로 변경하는 함수.\n",
    "    result = []\n",
    "    for sequence in sequences: # 전체 시퀀스로부터 시퀀스를 하나씩 꺼낸다.\n",
    "        temp = []\n",
    "        for pred in sequence: # 시퀀스로부터 예측값을 하나씩 꺼낸다.\n",
    "            pred_index = np.argmax( pred ) # 예를 들어 [0, 0, 1, 0 ,0]라면 1의 인덱스인 2를 리턴한다.\n",
    "            temp.append( index_to_ner[ pred_index ].replace( \"PAD\", \"O\" ) ) # 'PAD'는 'O'로 변경\n",
    "        result.append( temp )\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = model.predict( X_test )\n",
    "pred_tags = sequences_to_tag( y_predicted )\n",
    "test_tags = sequences_to_tag( y_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( classification_report( test_tags, pred_tags ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( \"F1-score: {:.1%}\".format( f1_score( test_tags, pred_tags ) ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 새로운 입력에 대한 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index = src_tokenizer.word_index\n",
    "new_sentence = 'Hong Gildong starts over with the Justice League of Joseon at the country of Yul'.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X = []\n",
    "for w in new_sentence:\n",
    "    try:\n",
    "      new_X.append( word_to_index.get( w, 1 ) )\n",
    "    except KeyError:\n",
    "      new_X.append( word_to_index[ 'OOV' ] )\n",
    "      # 모델이 모르는 단어에 대해서는 'OOV'의 인덱스인 1로 인코딩\n",
    "\n",
    "print( new_X )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_new = pad_sequences( [ new_X ], padding = \"post\", value = 0, maxlen = max_len )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = model.predict( np.array( [ pad_new[ 0 ] ] ) )\n",
    "p = np.argmax( p, axis = -1 )\n",
    "print( \"{:15}||{}\".format( \"단어\", \"예측값\" ) )\n",
    "print( 30 * \"=\" )\n",
    "for w, pred in zip( new_sentence, p[ 0 ] ):\n",
    "    print( \"{:15}: {:5}\".format( w, index_to_ner[ pred ] ) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
