{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 원-핫 인코딩( One-hot encoding )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 컴퓨터 또는 기계는 문자보다는 숫자를 더 잘 처리할 수 있다. 자연어 처리에서는 문자를 숫자로 바꾸는 여러가지 기법이 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 원-핫 인코딩( One-hot encoding )은 그 많은 기법 중에서 단어를 표현하는 가장 기본적인 표현 방법이며, 머신 러닝, 딥 러닝을 하기 위해서는 반드시 배워야 하는 표현 방법이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 단어 집합( vocabulary ) 또는 사전( vocabulary )이라고도 부른다. 단어 집합은 서로 다른 단어들의 집합이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 단어 집합( vocabulary )에서는 기본적으로 book과 books와 같이 단어의 변형 형태도 다른 단어로 간주한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 원-핫 인코딩을 위해서 먼저 해야할 일은 단어 집합을 만드는 일이다. 텍스트의 모든 단어를 중복을 허용하지 않고 모아놓으면 이를 단어 집합이라고 한다. 그리고 이 단어 집합에 고유한 숫자를 부여하는 정수 인코딩을 진행한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 원-핫 인코딩( One-hot encoding )이란?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 원-핫 인코딩은 단어 집합의 크기를 벡터의 차원으로 하고, 표현하고 싶은 단어의 인덱스에 1의 값을 부여하고, 다른 인덱스에는 0을 부여하는 벡터 표현 방식이다. 이렿게 표현된 벡터를 원-핫 벡터( One-hot vector )라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 원-핫 인코딩을 두 가지 과정으로 정리\n",
    "#### (1) 각 단어에 고유한 인덱스를 부여한다.( 정수 인코딩 )\n",
    "#### (2) 표현하고 싶은 단어의 인덱스의 위치에 1을 부여하고, 다른 단어의 인덱스의 위치에는 0을 부여한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Okt 형태소 분석기를 통해 문자에 대한 토큰화 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['나', '는', '자연어', '처리', '를', '배운다', '.']\n"
     ]
    }
   ],
   "source": [
    "okt = Okt()\n",
    "token = okt.morphs( \"나는 자연어 처리를 배운다.\" )\n",
    "print( token )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 각 토큰에 대해 고유한 index를 부여한다. 빈도수 순대로 단어를 정렬하여 고유한 index를 부여하는 작업이 사용되기도 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'나': 0, '는': 1, '자연어': 2, '처리': 3, '를': 4, '배운다': 5, '.': 6}\n"
     ]
    }
   ],
   "source": [
    "word2index = {}\n",
    "for voca in token:\n",
    "    if voca not in word2index.keys():\n",
    "        word2index[ voca ] = len( word2index )\n",
    "print( word2index )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 토큰을 입력하면 해당 토큰에 대한 원-핫 벡터를 만들어내는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding( word, word2index ):\n",
    "    one_hot_vector = [ 0 ] * ( len( word2index ) )\n",
    "    index = word2index[ word ]\n",
    "    one_hot_vector[ index ] = 1\n",
    "    \n",
    "    return one_hot_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_encoding( \"자연어\", word2index )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### one_hot_encoding()에 '자연어'라는 토큰을 입력으로 하면 [ 0, 0, 1, 0, 0, 0 ] 라는 벡터가 리턴된다. '자연어'는 단어 집합에서 index가 2이므로, '자연어'를 표현하는 원-핫 벡터는 인덱스 2의 값이 1이며, 나머지 값은 0인 벡터가 나온다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Keras를 이용한 원-핫 인코딩( One-hot encoding )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Keras는 원-핫 인코딩을 수행하는 유용한 도구인 to_categorical()를 지원한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"나랑 점심 먹으러 갈래 점심 메뉴는 햄버거 갈래 갈래 햄버거 최고야\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 정수 인코딩 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 정수 인코딩을 수행하여 단어 집합( vocabulary ) 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'갈래': 1, '점심': 2, '햄버거': 3, '나랑': 4, '먹으러': 5, '메뉴는': 6, '최고야': 7}\n"
     ]
    }
   ],
   "source": [
    "t = Tokenizer()\n",
    "t.fit_on_texts( [ text ] )\n",
    "print( t.word_index ) # 각 단어에 대한 정수 인코딩 결과"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 위와 같이 생성된 단어 집합( vocabulary )에 있는 단어들로만 구성된 텍스트가 있다면, texts_to_sequences()를 통해서 이를 정수 시퀀스로 변환가능하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 5, 1, 6, 3, 7]\n"
     ]
    }
   ],
   "source": [
    "sub_text = \"점심 먹으러 갈래 메뉴는 햄버거 최고야\"\n",
    "encoded = t.texts_to_sequences( [ sub_text] )[ 0 ]\n",
    "print( encoded )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 위의 결과를 가지고 원-핫 인코딩을 진행한다. Keras는 정수 인코딩 된 결과로 부터 원-핫 인코딩을 수행하는 to_categorical()를 지원한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "one_hot = to_categorical( encoded )\n",
    "print( one_hot )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 원-핫 인코딩( One-hot encoding )의 한계"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 이러한 표현 방식은 단어의 개수가 늘어날 수록, 벡터를 저장하기 위해 필요한 공간이 계속 늘어난다는 단점이 있다. 다른 말로는 벡터의 차원이 계속 늘어난다고도 표현한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 원-핫 벡터는 단어 집합의 크기가 곧 벡터의 차원 수가 된다. 예로 단어가 1000개인 corpus를 가지고 원-핫 벡터를 만들면, 모든 단어 각각은 모두 1000개의 차원을 가진 벡터가 된다. 다시 말해 모든 단어 각각은 하나의 값만 1을 가지고, 999개의 값은 0의 값을 가지는 벡터가 되는데 이는 저장 공간 측면에서는 매우 비효율적인 표현 방법이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 또한 원-핫 벡터는 단어의 유사도을 표현하지 못한다는 단점이 있다. 단어 간 유사성을 알 수 없다는 단점은 검색 시스템 등에서 심각한 문제인다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 이러한 단점을 해결하기 위해 단어의 잠재 의미를 반영하여 다차원 공간에 베터화 하는 기법으로 크게 두 가지가 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 첫째는 카운트 기반의 베터화 방법인 LSA, HAL 등이 있으며, 둘째는 예측 기반으로 벡터화하는 NNLM, RNNLM, Word2Vec, FastText 등이 있다. 그리고 카운트 기반과 예측 기반 두 가지 방법을 모두 사용하는 방법으로 GloVe라는 방법이 존재한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
